{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: orange;\"> 1. Setup Working Environment and constants </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARS.csv  CUSTOMERS.csv  HOUSEHOLDS.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare constant paths\n",
    "DATA_DIR        =   \"/home/jovyan/data\"\n",
    "CARS_CSV        =   f\"{DATA_DIR}/CARS.csv\"\n",
    "CUSTOMERS_CSV   =   f\"{DATA_DIR}/CUSTOMERS.csv\"\n",
    "HOUSEHOLDS_CSV  =   f\"{DATA_DIR}/HOUSEHOLDS.csv\"\n",
    "OUTPUT_DIR        =   \"/home/jovyan/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7a77421ed90e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SF-Data-Engineering-Work-Sample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffd8acdd50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"SF-Data-Engineering-Work-Sample\") \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "                    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "                    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: orange;\"> 2. Load all the Datasets </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FIRST 5 Records from CARS:\n",
      "------------------------------ \n",
      "\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+----------------------+\n",
      "|Car ID|  Status|State|Model Year|         Make|Body Style|Vehicle Value|Annual Miles Driven|Business Use|Antique Vehicle|Lien|Lease|Driver Safety Discount|Vehicle Safety Discount|Claim Payout|6 Month Premium Amount|\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+----------------------+\n",
      "|844435|In Force|   OK|      1990|Manufacturer7|    4 door|      50000.0|                 56|           0|              1|   1|    0|                     0|                      1|           0|                 42.89|\n",
      "|410619|In Force|   OK|      2019|Manufacturer5|       SUV|      8151.75|              12136|           0|              0|   0|    1|                     0|                      1|           0|           58.88769523|\n",
      "|192812|In Force|   OK|      2008|Manufacturer2|       SUV|       1651.2|              14674|           0|              0|   1|    0|                     0|                      1|           0|            322.307381|\n",
      "|752033|In Force|   OK|      1973|Manufacturer2|     Truck|        500.0|              15762|           0|              0|   1|    0|                     0|                      0|           0|            232.670242|\n",
      "| 23783|In Force|   NY|      2022|Manufacturer3|       SUV|      18873.9|              10154|           0|              0|   1|    0|                     0|                      1|           0|           167.4320143|\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Schema for CARS:\n",
      "------------------------------ \n",
      "\n",
      "root\n",
      " |-- Car ID: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Model Year: integer (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Vehicle Value: double (nullable = true)\n",
      " |-- Annual Miles Driven: integer (nullable = true)\n",
      " |-- Business Use: integer (nullable = true)\n",
      " |-- Antique Vehicle: integer (nullable = true)\n",
      " |-- Lien: integer (nullable = true)\n",
      " |-- Lease: integer (nullable = true)\n",
      " |-- Driver Safety Discount: integer (nullable = true)\n",
      " |-- Vehicle Safety Discount: integer (nullable = true)\n",
      " |-- Claim Payout: integer (nullable = true)\n",
      " |-- 6 Month Premium Amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the CARS_CSV file into a Spark DataFrame\n",
    "cars_df = spark.read.csv(CARS_CSV, header=True, inferSchema=True)\n",
    "\n",
    "print('-'*30)\n",
    "print('FIRST 5 Records from CARS:')\n",
    "print('-'*30, '\\n')\n",
    "cars_df.show(5)\n",
    "\n",
    "print('\\n')\n",
    "print('-'*30)\n",
    "print('Schema for CARS:')\n",
    "print('-'*30, '\\n')\n",
    "cars_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FIRST 5 Records from CUSTOMERS:\n",
      "------------------------------ \n",
      "\n",
      "+---------+-------------+--------------+--------------------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|  CUST_ID|Date of Birth|Marital Status|     Employment Type|Income| _c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|_c18|_c19|\n",
      "+---------+-------------+--------------+--------------------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|801198110|      11/6/02|             D|             Student|     0|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|281855167|      6/23/55|             D|             Retired|     0|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|688373183|      8/16/96|             M|Office and Admini...| 42052|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|752746800|      8/22/36|             M|             Retired|     0|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|114187354|      3/18/08|             D|   Sales and Related| 60879|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "+---------+-------------+--------------+--------------------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Schema for CUSTOMERS:\n",
      "------------------------------ \n",
      "\n",
      "root\n",
      " |-- CUST_ID: integer (nullable = true)\n",
      " |-- Date of Birth: string (nullable = true)\n",
      " |-- Marital Status: string (nullable = true)\n",
      " |-- Employment Type: string (nullable = true)\n",
      " |-- Income: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the CUSTOMERS_CSV file into a Spark DataFrame\n",
    "customers_df = spark.read.csv(CUSTOMERS_CSV, header=True, inferSchema=True)\n",
    "print('-'*30)\n",
    "print('FIRST 5 Records from CUSTOMERS:')\n",
    "print('-'*30, '\\n')\n",
    "customers_df.show(5)\n",
    "\n",
    "print('\\n')\n",
    "print('-'*30)\n",
    "print('Schema for CUSTOMERS:')\n",
    "print('-'*30, '\\n')\n",
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "FIRST 5 Records from HOUSEHOLDS:\n",
      "----------------------------------- \n",
      "\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|    HH_ID|  CUST_ID|CAR_ID|Active HH|HH Start Date|  Phone Number| ZIP |State|Country|Referral Source|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|219790301|801198110|844435|        1|     11/18/22|(709) 379-9036|70442|   OK|    USA|          Other|\n",
      "|219790301|281855167|410619|        1|     11/18/22|(740) 565-4060|70442|   OK|    USA|          Other|\n",
      "|219790301|688373183|192812|        1|     11/18/22|(117) 457-9582|70442|   OK|    USA|          Other|\n",
      "|219790301|752746800|752033|        1|     11/18/22|(536) 797-5920|70442|   OK|    USA|          Other|\n",
      "|464806390|114187354| 23783|        1|      10/9/20|(152) 373-1773|42706|   NY|    USA|          Event|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Schema for HOUSEHOLDS:\n",
      "----------------------------------- \n",
      "\n",
      "root\n",
      " |-- HH_ID: integer (nullable = true)\n",
      " |-- CUST_ID: integer (nullable = true)\n",
      " |-- CAR_ID: integer (nullable = true)\n",
      " |-- Active HH: integer (nullable = true)\n",
      " |-- HH Start Date: string (nullable = true)\n",
      " |-- Phone Number: string (nullable = true)\n",
      " |-- ZIP : integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Referral Source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the HOUSEHOLDS_CSV file into a Spark DataFrame\n",
    "households_df = spark.read.csv(HOUSEHOLDS_CSV, header=True, inferSchema=True)\n",
    "print('-'*35)\n",
    "print('FIRST 5 Records from HOUSEHOLDS:')\n",
    "print('-'*35, '\\n')\n",
    "households_df.show(5)\n",
    "\n",
    "print('\\n')\n",
    "print('-'*35)\n",
    "print('Schema for HOUSEHOLDS:')\n",
    "print('-'*35, '\\n')\n",
    "households_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: orange;\"> 3. Initial Data Cleaning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***The column names contain spaces and are inconsistent across the datasets, not adhering to best practices. Fixing them below:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Updated CARS Schema:\n",
      "----------------------------------- \n",
      "\n",
      "root\n",
      " |-- car_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- model_year: integer (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- body_style: string (nullable = true)\n",
      " |-- vehicle_value: double (nullable = true)\n",
      " |-- annual_miles_driven: integer (nullable = true)\n",
      " |-- business_use: integer (nullable = true)\n",
      " |-- antique_vehicle: integer (nullable = true)\n",
      " |-- lien: integer (nullable = true)\n",
      " |-- lease: integer (nullable = true)\n",
      " |-- driver_safety_discount: integer (nullable = true)\n",
      " |-- vehicle_safety_discount: integer (nullable = true)\n",
      " |-- claim_payout: integer (nullable = true)\n",
      " |-- six_month_premium_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns in CARS DataFrame following best practices\n",
    "cars_df   =  cars_df.withColumnRenamed('Car ID', 'car_id') \\\n",
    "                    .withColumnRenamed('Status', 'status') \\\n",
    "                    .withColumnRenamed('State', 'state') \\\n",
    "                    .withColumnRenamed('Model Year', 'model_year') \\\n",
    "                    .withColumnRenamed('Make', 'make') \\\n",
    "                    .withColumnRenamed('Body Style', 'body_style') \\\n",
    "                    .withColumnRenamed('Vehicle Value', 'vehicle_value') \\\n",
    "                    .withColumnRenamed('Annual Miles Driven', 'annual_miles_driven') \\\n",
    "                    .withColumnRenamed('Business Use', 'business_use') \\\n",
    "                    .withColumnRenamed('Antique Vehicle', 'antique_vehicle') \\\n",
    "                    .withColumnRenamed('Lien', 'lien') \\\n",
    "                    .withColumnRenamed('Lease', 'lease') \\\n",
    "                    .withColumnRenamed('Driver Safety Discount', 'driver_safety_discount') \\\n",
    "                    .withColumnRenamed('Vehicle Safety Discount', 'vehicle_safety_discount') \\\n",
    "                    .withColumnRenamed('Claim Payout', 'claim_payout') \\\n",
    "                    .withColumnRenamed('6 Month Premium Amount', 'six_month_premium_amount')\n",
    "\n",
    "print('-'*35)\n",
    "print(f\"Updated CARS Schema:\")\n",
    "print('-'*35, '\\n')\n",
    "\n",
    "cars_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Updated CUSTOMERS Schema:\n",
      "----------------------------------- \n",
      "\n",
      "root\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df = customers_df.withColumnRenamed('CUST_ID', 'cust_id') \\\n",
    "                            .withColumnRenamed('Date of Birth', 'date_of_birth') \\\n",
    "                            .withColumnRenamed('Marital Status', 'marital_status') \\\n",
    "                            .withColumnRenamed('Employment Type', 'employment_type') \\\n",
    "                            .withColumnRenamed('Income', 'income')\n",
    "\n",
    "print('-'*35)\n",
    "print(f\"Updated CUSTOMERS Schema:\")\n",
    "print('-'*35, '\\n')\n",
    "\n",
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Updated HOUSEHOLDS Schema:\n",
      "----------------------------------- \n",
      "\n",
      "root\n",
      " |-- hh_id: integer (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- car_id: integer (nullable = true)\n",
      " |-- active_hh: integer (nullable = true)\n",
      " |-- hh_start_date: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- referral_source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns in HOUSEHOLDS DataFrame following best practices\n",
    "households_df = households_df.withColumnRenamed('HH_ID', 'hh_id') \\\n",
    "                                .withColumnRenamed('CUST_ID', 'cust_id') \\\n",
    "                                .withColumnRenamed('CAR_ID', 'car_id') \\\n",
    "                                .withColumnRenamed('Active HH', 'active_hh') \\\n",
    "                                .withColumnRenamed('HH Start Date', 'hh_start_date') \\\n",
    "                                .withColumnRenamed('Phone Number', 'phone_number') \\\n",
    "                                .withColumnRenamed('ZIP ', 'zip') \\\n",
    "                                .withColumnRenamed('State', 'state') \\\n",
    "                                .withColumnRenamed('Country', 'country') \\\n",
    "                                .withColumnRenamed('Referral Source', 'referral_source')\n",
    "\n",
    "print('-'*35)\n",
    "print(f\"Updated HOUSEHOLDS Schema:\")\n",
    "print('-'*35, '\\n')\n",
    "\n",
    "households_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- ***From the sample records in Section 2, the CUSTOMERS DataFrame seems to have unnecessary (blank) columns. Checking if they can be dropped to reduce data size before combining the datasets:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Null counts for each column:\n",
      "----------------------------------- \n",
      "\n",
      "+-------+-------------+--------------+---------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "|cust_id|date_of_birth|marital_status|employment_type|income|   _c5|   _c6|   _c7|   _c8|   _c9|  _c10|  _c11|  _c12|  _c13|  _c14|  _c15|  _c16|  _c17|  _c18|  _c19|\n",
      "+-------+-------------+--------------+---------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "|      0|            0|             0|              0|     0|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|499999|\n",
      "+-------+-------------+--------------+---------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in CUSTOMERS DF:\n",
      "----------------------------------- \n",
      "\n",
      "499999\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "cust_columns_to_check = customers_df.columns\n",
    "cust_null_count_expressions = [spark_sum(col(column).isNull().cast(\"int\")).alias(column) for column in cust_columns_to_check]\n",
    "cust_null_counts_df = customers_df.select(cust_null_count_expressions)\n",
    "\n",
    "print('-'*35)\n",
    "print(\"Null counts for each column:\")\n",
    "print('-'*35, '\\n')\n",
    "\n",
    "cust_null_counts_df.show()\n",
    "\n",
    "print('-'*35)\n",
    "print(\"Total rows in CUSTOMERS DF:\")\n",
    "print('-'*35, '\\n')\n",
    "\n",
    "total_cust_rows = customers_df.count()\n",
    "print(total_cust_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- ***All the records have null values in columns _c5 to _c19, so they can be dropped safely.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- date_of_birth: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [f'_c{i}' for i in range(5, 20)]     # all the columns from _c5 to _c19 only have NULL values.\n",
    "customers_df = customers_df.drop(*columns_to_drop)\n",
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- ***Now, all the columns in the CARS, CUSTOMERS, and HOUSEHOLDS DataFrames have some values.***\n",
    "  \n",
    "- ***We can handle any more NULL values after combining the DataFrames to avoid premature dropping of records or missing value imputation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Here is an overview of the number of NULL values per column in each DataFrame:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "CARS DataFrame:\n",
      "#################### \n",
      "\n",
      "-----------------------------------\n",
      "Null counts for CARS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|status|state|model_year|make|body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|     0|     0|    0|         0|   0|         0|            0|                  0|           0|              0|   0|    0|                     0|                      0|           0|                       0|\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in CARS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "500000\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "CUSTOMERS DataFrame:\n",
      "#################### \n",
      "\n",
      "-----------------------------------\n",
      "Null counts for CUSTOMERS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "|cust_id|date_of_birth|marital_status|employment_type|income|\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "|      0|            0|             0|              0|     0|\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in CUSTOMERS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "499999\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "HOUSEHOLDS DataFrame:\n",
      "#################### \n",
      "\n",
      "-----------------------------------\n",
      "Null counts for HOUSEHOLDS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "|hh_id|cust_id|car_id|active_hh|hh_start_date|phone_number|zip|state|country|referral_source|\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "|    0|      0|     0|        0|            0|           0|  0|    0|      0|              0|\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in HOUSEHOLDS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "500000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "def calculate_null_counts(df, df_name):\n",
    "    print(\"#\"*20)\n",
    "    print(f\"{df_name} DataFrame:\")\n",
    "    print(\"#\"*20, \"\\n\")\n",
    "\n",
    "    null_count_expressions = [spark_sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns]\n",
    "    null_counts_df = df.select(null_count_expressions)\n",
    "    total_rows = df.count()\n",
    "    \n",
    "    print('-'*35)\n",
    "    print(f\"Null counts for {df_name} DataFrame:\")\n",
    "    print('-'*35, '\\n')\n",
    "    null_counts_df.show()\n",
    "\n",
    "    print('-'*35)\n",
    "    print(f\"Total rows in {df_name} DataFrame:\")\n",
    "    print('-'*35, '\\n')\n",
    "    print(total_rows)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# Calculate null counts for CARS DataFrame\n",
    "calculate_null_counts(cars_df, \"CARS\")\n",
    "\n",
    "# Calculate null counts for CUSTOMERS DataFrame\n",
    "calculate_null_counts(customers_df, \"CUSTOMERS\")\n",
    "\n",
    "# Calculate null counts for HOUSEHOLDS DataFrame\n",
    "calculate_null_counts(households_df, \"HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- ***There aren't any NULL values in the datasets now.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Sample records from CARS DataFrame:\n",
      "######################################## \n",
      "\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|  status|state|model_year|         make|body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|844435|In Force|   OK|      1990|Manufacturer7|    4 door|      50000.0|                 56|           0|              1|   1|    0|                     0|                      1|           0|                   42.89|\n",
      "|410619|In Force|   OK|      2019|Manufacturer5|       SUV|      8151.75|              12136|           0|              0|   0|    1|                     0|                      1|           0|             58.88769523|\n",
      "|192812|In Force|   OK|      2008|Manufacturer2|       SUV|       1651.2|              14674|           0|              0|   1|    0|                     0|                      1|           0|              322.307381|\n",
      "|752033|In Force|   OK|      1973|Manufacturer2|     Truck|        500.0|              15762|           0|              0|   1|    0|                     0|                      0|           0|              232.670242|\n",
      "| 23783|In Force|   NY|      2022|Manufacturer3|       SUV|      18873.9|              10154|           0|              0|   1|    0|                     0|                      1|           0|             167.4320143|\n",
      "+------+--------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n",
      "########################################\n",
      "Sample records from CUSTOMERS DataFrame:\n",
      "######################################## \n",
      "\n",
      "+---------+-------------+--------------+--------------------+------+\n",
      "|  cust_id|date_of_birth|marital_status|     employment_type|income|\n",
      "+---------+-------------+--------------+--------------------+------+\n",
      "|801198110|      11/6/02|             D|             Student|     0|\n",
      "|281855167|      6/23/55|             D|             Retired|     0|\n",
      "|688373183|      8/16/96|             M|Office and Admini...| 42052|\n",
      "|752746800|      8/22/36|             M|             Retired|     0|\n",
      "|114187354|      3/18/08|             D|   Sales and Related| 60879|\n",
      "+---------+-------------+--------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n",
      "########################################\n",
      "Sample records from HOUSEHOLDS DataFrame:\n",
      "######################################## \n",
      "\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|    hh_id|  cust_id|car_id|active_hh|hh_start_date|  phone_number|  zip|state|country|referral_source|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|219790301|801198110|844435|        1|     11/18/22|(709) 379-9036|70442|   OK|    USA|          Other|\n",
      "|219790301|281855167|410619|        1|     11/18/22|(740) 565-4060|70442|   OK|    USA|          Other|\n",
      "|219790301|688373183|192812|        1|     11/18/22|(117) 457-9582|70442|   OK|    USA|          Other|\n",
      "|219790301|752746800|752033|        1|     11/18/22|(536) 797-5920|70442|   OK|    USA|          Other|\n",
      "|464806390|114187354| 23783|        1|      10/9/20|(152) 373-1773|42706|   NY|    USA|          Event|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "def show_sample_records(df, df_name):\n",
    "    print(\"#\"*40)\n",
    "    print(f\"Sample records from {df_name} DataFrame:\")\n",
    "    print(\"#\"*40, \"\\n\")\n",
    "    df.show(5)\n",
    "    print(\"\\n\")\n",
    "\n",
    "show_sample_records(cars_df, \"CARS\")\n",
    "show_sample_records(customers_df, \"CUSTOMERS\")\n",
    "show_sample_records(households_df, \"HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Checking for duplicate records before merging the DataFrames to avoid unintended joins.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No fully duplicated rows found in CARS DataFrame.\n",
      "No fully duplicated rows found in CUSTOMERS DataFrame.\n",
      "No fully duplicated rows found in HOUSEHOLDS DataFrame.\n"
     ]
    }
   ],
   "source": [
    "def check_for_full_duplicates(df, df_name):\n",
    "    total_count = df.count()\n",
    "    unique_count = df.dropDuplicates().count()\n",
    "    duplicate_count = total_count - unique_count\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"{df_name} DataFrame has has {duplicate_count} fully duplicated rows.\")\n",
    "    else:\n",
    "        print(f\"No fully duplicated rows found in {df_name} DataFrame.\")\n",
    "\n",
    "check_for_full_duplicates(cars_df, \"CARS\")\n",
    "check_for_full_duplicates(customers_df, \"CUSTOMERS\")\n",
    "check_for_full_duplicates(households_df, \"HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARS DataFrame has 95051 duplicate records based on car_id.\n",
      "CUSTOMERS DataFrame has 149 duplicate records based on cust_id.\n",
      "HOUSEHOLDS DataFrame has 131352 duplicate records based on hh_id.\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(df, primary_key, df_name):\n",
    "    duplicate_count = df.groupBy(primary_key).count().filter(\"count > 1\").count()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"{df_name} DataFrame has {duplicate_count} duplicate records based on {primary_key}.\")\n",
    "    else:\n",
    "        print(f\"No duplicate records found in {df_name}  DataFrame based on {primary_key}.\")\n",
    "\n",
    "check_duplicates(cars_df, \"car_id\", \"CARS\")\n",
    "check_duplicates(customers_df, \"cust_id\", \"CUSTOMERS\")\n",
    "check_duplicates(households_df, \"hh_id\", \"HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- ***Approximately 20% of records in CARS, 0.03% of records in CUSTOMERS, and 26% of records in HOUSEHOLDS have duplicate IDs, which is not ideal.***\n",
    "\n",
    "- ***Inspect the duplicate records to take a strategic approach in handling them without losing valuable information.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records in CARS DataFrame based on car_id:\n",
      "+------+---------------------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|status               |state|model_year|make         |body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+---------------------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|7982  |Customer Cancellation|HI   |2018      |Manufacturer7|2 door    |27416.9      |5898               |0           |0              |1   |0    |0                     |1                      |0           |156.8435672             |\n",
      "|7982  |Customer Cancellation|VT   |2017      |Manufacturer2|2 door    |5534.75      |1238               |0           |0              |0   |0    |0                     |0                      |0           |404.711789              |\n",
      "|7982  |In Force             |CO   |1974      |Manufacturer3|4 door    |500.0        |4462               |0           |0              |1   |0    |0                     |1                      |0           |180.1025444             |\n",
      "|40653 |In Force             |MN   |2004      |Manufacturer4|4 door    |500.0        |47201              |0           |0              |0   |1    |0                     |1                      |0           |252.6472318             |\n",
      "|40653 |In Force             |WV   |2023      |Manufacturer1|Truck     |45205.75     |63719              |0           |0              |1   |0    |0                     |0                      |0           |498.2874638             |\n",
      "|40653 |In Force             |MT   |2006      |Manufacturer3|4 door    |2095.4       |3776               |0           |0              |1   |0    |0                     |1                      |0           |55.29279544             |\n",
      "|101055|Customer Cancellation|AZ   |1990      |Manufacturer3|SUV       |500.0        |10532              |0           |0              |1   |0    |0                     |1                      |0           |414.2478138             |\n",
      "|101055|In Force             |SC   |2022      |Manufacturer3|2 door    |10289.7      |7649               |0           |0              |1   |0    |0                     |1                      |0           |199.1287359             |\n",
      "|528755|In Force             |WY   |2019      |Manufacturer2|2 door    |5677.5       |12555              |0           |0              |1   |0    |0                     |1                      |0           |479.9069774             |\n",
      "|528755|Customer Cancellation|MT   |2014      |Manufacturer7|SUV       |21697.0      |12431              |0           |0              |0   |0    |0                     |0                      |0           |52.20778075             |\n",
      "|528755|In Force             |VA   |2020      |Manufacturer1|2 door    |24862.4      |78844              |0           |0              |0   |1    |1                     |1                      |0           |58.44203646             |\n",
      "|761106|In Force             |OR   |2016      |Manufacturer3|SUV       |14310.0      |57382              |0           |0              |1   |0    |1                     |0                      |0           |312.0992839             |\n",
      "|761106|In Force             |IA   |2024      |Manufacturer5|4 door    |13241.0      |6321               |0           |0              |1   |0    |0                     |1                      |0           |455.6356386             |\n",
      "+------+---------------------+-----+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Function to inspect duplicate records based on 'id' columns\n",
    "def inspect_duplicates(df, primary_key, df_name):\n",
    "    duplicate_keys = df.groupBy(primary_key).count().filter(\"count > 1\").select(primary_key).limit(5)  # Limiting to 5 for inspection\n",
    "    duplicates = df.join(duplicate_keys, on=primary_key, how='inner').orderBy(primary_key)\n",
    "\n",
    "    print(f\"Duplicate records in {df_name} DataFrame based on {primary_key}:\")\n",
    "    duplicates.show(truncate=False)\n",
    "\n",
    "# Inspect duplicates in CARS DataFrame\n",
    "inspect_duplicates(cars_df, \"car_id\", \"CARS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|status               |\n",
      "+---------------------+\n",
      "|In Force             |\n",
      "|Company Cancellation |\n",
      "|Non Pay              |\n",
      "|Customer Cancellation|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_status_values = cars_df.select(\"status\").distinct()\n",
    "distinct_status_values.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate count for car_id + status: 78948\n",
      "Duplicate count for car_id + state: 0\n",
      "Duplicate count for car_id + model_year: 4252\n",
      "Duplicate count for car_id + make: 24730\n"
     ]
    }
   ],
   "source": [
    "# Define a function to check and print duplicate count based on a combination of columns\n",
    "def check_combination_duplicates(df, columns, combination_name):\n",
    "    duplicate_count = df.groupBy(columns).count().filter(\"count > 1\").count()\n",
    "    print(f\"Duplicate count for {combination_name}: {duplicate_count}\")\n",
    "\n",
    "# Checking duplicates for different combinations of columns\n",
    "check_combination_duplicates(cars_df, [\"car_id\", \"status\"], \"car_id + status\")\n",
    "check_combination_duplicates(cars_df, [\"car_id\", \"state\"], \"car_id + state\")\n",
    "check_combination_duplicates(cars_df, [\"car_id\", \"model_year\"], \"car_id + model_year\")\n",
    "check_combination_duplicates(cars_df, [\"car_id\", \"make\"], \"car_id + make\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "\n",
    " ***The above stats indicate that (car_id, state) form a unique combination in the CARS dataset, meaning that car_ids may have been assigned uniquely for each state instead of globally.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***DQ Checks for CARS DataFrame:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of invalid state records: 0\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|status|state|model_year|make|body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "+------+------+-----+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "\n",
      "Records with invalid model_year: 0\n",
      "+-------------+\n",
      "|make         |\n",
      "+-------------+\n",
      "|Manufacturer5|\n",
      "|Manufacturer7|\n",
      "|Manufacturer1|\n",
      "|Manufacturer3|\n",
      "|Manufacturer2|\n",
      "|Manufacturer4|\n",
      "|Manufacturer6|\n",
      "+-------------+\n",
      "\n",
      "+----------+\n",
      "|body_style|\n",
      "+----------+\n",
      "|4 door    |\n",
      "|SUV       |\n",
      "|Truck     |\n",
      "|2 door    |\n",
      "+----------+\n",
      "\n",
      "Records with negative vehicle_value: 0\n",
      "Records with negative annual_miles_driven: 0\n",
      "Records with invalid business_use values: 0\n",
      "Records with invalid antique_vehicle: 0\n",
      "Records where lien and lease are 1: 0\n",
      "Records with invalid discount for canceled vehicles: 31708\n",
      "Records with negative annual_miles_driven: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import year, current_date\n",
    "\n",
    "# Check if state is valid\n",
    "valid_states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "invalid_states_df = cars_df.filter(~col(\"state\").isin(valid_states))\n",
    "invalid_state_count = invalid_states_df.count()\n",
    "print(f\"Count of invalid state records: {invalid_state_count}\")\n",
    "invalid_states_df.show(5)\n",
    "\n",
    "# Model year not in a valid range\n",
    "model_year_outliers = cars_df.filter((F.col(\"model_year\") < 1900) | (F.col(\"model_year\") > 2024)).count()\n",
    "print(f\"Records with invalid model_year: {model_year_outliers}\")\n",
    "\n",
    "# Check if 'Make' values are valid\n",
    "distinct_make_values = cars_df.select(\"make\").distinct()\n",
    "distinct_make_values.show(truncate=False)\n",
    "\n",
    "# Check if 'body_style' values are valid\n",
    "distinct_body_style_values = cars_df.select(\"body_style\").distinct()\n",
    "distinct_body_style_values.show(truncate=False)\n",
    "\n",
    "# Check if Vehicle value is negative\n",
    "vehicle_value_outliers = cars_df.filter(F.col(\"vehicle_value\") < 0).count()\n",
    "print(f\"Records with negative vehicle_value: {vehicle_value_outliers}\")\n",
    "\n",
    "# Check if Annual miles driven is negative\n",
    "miles_driven_outliers = cars_df.filter(F.col(\"annual_miles_driven\") < 0).count()\n",
    "print(f\"Records with negative annual_miles_driven: {miles_driven_outliers}\")\n",
    "\n",
    "\n",
    "# Check if Business Use is non-binary:\n",
    "invalid_business_use = cars_df.filter((F.col(\"business_use\") != 0) & (F.col(\"business_use\") != 1)).count()\n",
    "print(f\"Records with invalid business_use values: {invalid_business_use}\")\n",
    "\n",
    "# Antique vehicle should be older than 25 years\n",
    "invalid_antique_vehicle = cars_df.filter((F.col(\"antique_vehicle\") == 1) & (F.col(\"model_year\") >= (year(current_date()) - 25))).count()\n",
    "print(f\"Records with invalid antique_vehicle: {invalid_antique_vehicle}\")\n",
    "\n",
    "# Check if both lien and lease are 1\n",
    "invalid_lien_lease = cars_df.filter((F.col(\"lease\") == 1) & (F.col(\"lien\") == 1) ).count()\n",
    "print(f\"Records where lien and lease are 1: {invalid_lien_lease}\")\n",
    "\n",
    "# Check for discrepancy in Discount Logic (discounts should be 0 if status=\"Customer Cancelled\")\n",
    "invalid_discount_status = cars_df.filter((F.col(\"status\") == \"Customer Cancellation\") & ((F.col(\"driver_safety_discount\") == 1) | (F.col(\"vehicle_safety_discount\") == 1))).count()\n",
    "print(f\"Records with invalid discount for canceled vehicles: {invalid_discount_status}\")\n",
    "\n",
    "# Check if six_month_premium_amount is negative\n",
    "amount_outliers = cars_df.filter(F.col(\"six_month_premium_amount\") < 0).count()\n",
    "print(f\"Records with negative annual_miles_driven: {amount_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records in CUSTOMERS DataFrame based on cust_id:\n",
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "|cust_id  |date_of_birth|marital_status|employment_type                  |income|\n",
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "|227538866|2/18/49      |S             |Retired                          |0     |\n",
      "|227538866|4/7/92       |M             |Information Technology           |94119 |\n",
      "|312991279|1/26/51      |S             |Retired                          |0     |\n",
      "|312991279|5/6/50       |M             |Retired                          |0     |\n",
      "|461580480|3/26/99      |M             |Sales and Related                |44900 |\n",
      "|461580480|9/23/91      |M             |Education, Training, and Library |51942 |\n",
      "|471247910|2/28/08      |S             |Healthcare Practitioner          |203297|\n",
      "|471247910|6/21/94      |S             |Management                       |146625|\n",
      "|602067883|2/20/74      |M             |Office and Administrative Support|40391 |\n",
      "|602067883|1/20/84      |S             |Management                       |107293|\n",
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect duplicates in CUSTOMERS DataFrame\n",
    "inspect_duplicates(customers_df, \"cust_id\", \"CUSTOMERS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|count_of_records|number_of_cust_ids|\n",
      "+----------------+------------------+\n",
      "|1               |499701            |\n",
      "|2               |149               |\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check number of cust_ids having count > 1\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "cust_id_counts = customers_df.groupBy(\"cust_id\").agg(F.count(\"*\").alias(\"count_of_records\"))\n",
    "record_count_summary = cust_id_counts.groupBy(\"count_of_records\").agg(F.count(\"*\").alias(\"number_of_cust_ids\"))\n",
    "record_count_summary.orderBy(\"count_of_records\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|cust_id  |age_diff|\n",
      "+---------+--------+\n",
      "|109866437|0       |\n",
      "|168700118|26      |\n",
      "|227538866|43      |\n",
      "|312991279|1       |\n",
      "|420542258|22      |\n",
      "|440410970|39      |\n",
      "|461580480|8       |\n",
      "|471247910|86      |\n",
      "|519811680|28      |\n",
      "|536960589|25      |\n",
      "|547773814|81      |\n",
      "|574537471|60      |\n",
      "|602067883|10      |\n",
      "|693618114|85      |\n",
      "|738641435|52      |\n",
      "|764819779|44      |\n",
      "|770469307|42      |\n",
      "|810195055|22      |\n",
      "|932153522|12      |\n",
      "|949920394|65      |\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the age difference between records having same cust_ids to gauge possible relationships\n",
    "age_diff_df = (\n",
    "    customers_df\n",
    "    .groupBy(\"cust_id\")\n",
    "    .agg(\n",
    "        F.collect_list(\"date_of_birth\").alias(\"dob_list\")\n",
    "    )\n",
    "    .filter(F.size(\"dob_list\") == 2)  # To only consider the 149 cust_ids with exactly 2 DOBs\n",
    ")\n",
    "\n",
    "# Calculate the approximate age difference in years\n",
    "age_diff_result = age_diff_df.select(\n",
    "    \"cust_id\",\n",
    "    F.abs(F.year(F.to_date(F.col(\"dob_list\")[0], 'M/d/yy')) - F.year(F.to_date(F.col(\"dob_list\")[1], 'M/d/yy'))).alias(\"age_diff\")\n",
    ")\n",
    "\n",
    "age_diff_result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "- **The above results indicate that 0.06% of the cust_ids are duplicates, with a count of 2.**\n",
    "\n",
    "- **Given the age gaps (in years) as seen above, the duplicates could represent family members (e.g., spouses, siblings, children, or grandchildren) added to the same insurance account.**\n",
    "\n",
    "- **These individuals are ideally living in the same household as the primary insured.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "|cust_id  |date_of_birth|marital_status|employment_type                  |income|\n",
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "|100000879|4/5/34       |M             |Retired                          |0     |\n",
      "|100031685|10/3/01      |S             |Management                       |105253|\n",
      "|100043441|5/2/97       |M             |Student                          |0     |\n",
      "|100052059|4/18/80      |M             |Business and Financial Operations|95633 |\n",
      "|100090208|12/12/03     |S             |Student                          |0     |\n",
      "|100150473|4/9/31       |M             |Retired                          |0     |\n",
      "|100151275|5/6/97       |W             |Information Technology           |98536 |\n",
      "|100152292|9/18/00      |M             |Information Technology           |138003|\n",
      "|100154073|1/24/43      |M             |Retired                          |0     |\n",
      "|100175646|4/17/04      |D             |Information Technology           |136633|\n",
      "|100183609|7/18/03      |S             |Information Technology           |118388|\n",
      "|100187428|6/28/25      |M             |Retired                          |0     |\n",
      "|100188172|9/17/57      |M             |Retired                          |0     |\n",
      "|100189942|3/20/32      |M             |Retired                          |0     |\n",
      "|100218163|5/1/06       |D             |Healthcare Practitioner          |203896|\n",
      "|100224093|1/11/87      |M             |Information Technology           |109682|\n",
      "|100228308|3/25/40      |M             |Retired                          |0     |\n",
      "|100235431|10/3/92      |S             |Information Technology           |97191 |\n",
      "|100282816|6/22/84      |S             |Office and Administrative Support|40648 |\n",
      "|100285248|12/17/62     |D             |Retired                          |0     |\n",
      "+---------+-------------+--------------+---------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"cust_id\").orderBy(\"date_of_birth\")\n",
    "\n",
    "ranked_customers_df = (customers_df.withColumn(\"row_number\", F.row_number().over(window_spec)))\n",
    "\n",
    "new_cust_df = ranked_customers_df.filter(F.col(\"row_number\") == 1).drop(\"row_number\")\n",
    "\n",
    "new_cust_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499850"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cust_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records in CUSTOMERS DataFrame based on cust_id:\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "|cust_id|date_of_birth|marital_status|employment_type|income|\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "+-------+-------------+--------------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect duplicates in the new DataFrame\n",
    "inspect_duplicates(new_cust_df, \"cust_id\", \"CUSTOMERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***DQ Checks for CUSTOMERS DataFrame:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid date_of_birth count: 0\n",
      "Invalid marital_status count: 0\n",
      "Unique Employment types from CUSTOMERS DataFrame are:\n",
      "+---------------------------------+\n",
      "|employment_type                  |\n",
      "+---------------------------------+\n",
      "|Healthcare Practitioner          |\n",
      "|#REF!                            |\n",
      "|Student                          |\n",
      "|Management                       |\n",
      "|Information Technology           |\n",
      "|Education, Training, and Library |\n",
      "|Office and Administrative Support|\n",
      "|Business and Financial Operations|\n",
      "|Sales and Related                |\n",
      "|Retired                          |\n",
      "+---------------------------------+\n",
      "\n",
      "Invalid employment_type count: 0\n",
      "Invalid income count: 5464\n",
      "+---------+-------------+--------------+---------------+------+\n",
      "|cust_id  |date_of_birth|marital_status|employment_type|income|\n",
      "+---------+-------------+--------------+---------------+------+\n",
      "|100578501|10/24/88     |D             |#REF!          |#REF! |\n",
      "|101470240|1/22/88      |M             |#REF!          |#REF! |\n",
      "|102397748|5/15/79      |S             |#REF!          |#REF! |\n",
      "|103007287|2/24/84      |M             |#REF!          |#REF! |\n",
      "|105963373|6/23/98      |S             |#REF!          |#REF! |\n",
      "+---------+-------------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, when, isnan, length, count, sum as spark_sum, to_date, regexp_extract\n",
    "\n",
    "# Check for invalid date format or invalid date\n",
    "invalid_dob_count = new_cust_df.filter(\n",
    "                        # Either the format is incorrect\n",
    "                        (regexp_extract(col(\"date_of_birth\"), r\"^\\d{1,2}/\\d{1,2}/\\d{2}$\", 0) == \"\") | \n",
    "                        # Or the date is not valid\n",
    "                        (to_date(col(\"date_of_birth\"), \"M/d/yy\").isNull())\n",
    "                    ).count()\n",
    "print(f\"Invalid date_of_birth count: {invalid_dob_count}\")\n",
    "\n",
    "# Check for valid marital_status values (S: Single, M: Married, D: Divorced, W: Widowed)\n",
    "valid_marital_status_values = [\"S\", \"M\", \"D\", \"W\"]\n",
    "invalid_marital_status_count = new_cust_df.filter(~col(\"marital_status\").isin(valid_marital_status_values)).count()\n",
    "print(f\"Invalid marital_status count: {invalid_marital_status_count}\")\n",
    "\n",
    "# Check for valid employment_type (should not be null or empty)\n",
    "unique_employment_types = new_cust_df.select(\"employment_type\").distinct()\n",
    "print(\"Unique Employment types from CUSTOMERS DataFrame are:\")\n",
    "unique_employment_types.show(truncate=False)\n",
    "\n",
    "invalid_employment_type_df = new_cust_df.filter((col(\"employment_type\").isNull()) | (length(col(\"employment_type\")) == 0))\n",
    "invalid_employment_type_count = invalid_employment_type_df.count()\n",
    "print(f\"Invalid employment_type count: {invalid_employment_type_count}\")\n",
    "\n",
    "# Check for invalid income\n",
    "invalid_income_df = new_cust_df.filter(\n",
    "    col(\"income\").cast(\"float\").isNull() | (col(\"income\").cast(\"float\") < 0)\n",
    ")\n",
    "invalid_income_count = invalid_income_df.count()\n",
    "print(f\"Invalid income count: {invalid_income_count}\")\n",
    "invalid_income_df.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "\n",
    "- **The employment_type and income columns contain a few undesirable values (#REF!).**\n",
    "\n",
    "- **Replace #REF! with NULL instead of dropping the records and potentially losing valuable information.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------------+\n",
      "|null_employment_type_count|null_income_count|\n",
      "+--------------------------+-----------------+\n",
      "|                      5464|             5464|\n",
      "+--------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace \"#REF!\" with NULL in both employment_type and income columns\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "cleaned_cust_df = new_cust_df.withColumn(\n",
    "                                \"employment_type\", when(col(\"employment_type\") == \"#REF!\", None).otherwise(col(\"employment_type\"))\n",
    "                            ).withColumn(\n",
    "                                \"income\", when(col(\"income\") == \"#REF!\", None).otherwise(col(\"income\"))\n",
    "                            )\n",
    "\n",
    "null_counts = cleaned_cust_df.select(\n",
    "                                count(when(col(\"employment_type\").isNull() | isnan(col(\"employment_type\")), True)).alias(\"null_employment_type_count\"),\n",
    "                                count(when(col(\"income\").isNull() | isnan(col(\"income\")), True)).alias(\"null_income_count\")\n",
    "                            )\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records in HOUSEHOLDS DataFrame based on hh_id:\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|hh_id    |cust_id  |car_id|active_hh|hh_start_date|phone_number  |zip  |state|country|referral_source|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|219883100|276802922|15066 |1        |4/21/14      |(925) 972-9067|42362|TN   |USA    |Event          |\n",
      "|219883100|857918981|678149|1        |4/21/14      |(551) 512-6795|42362|TN   |USA    |Event          |\n",
      "|219883100|677506232|598410|1        |4/21/14      |(477) 286-9633|42362|TN   |USA    |Event          |\n",
      "|219883100|793331621|326708|1        |4/21/14      |(544) 387-2179|42362|TN   |USA    |Event          |\n",
      "|219883100|399267806|94351 |1        |4/21/14      |(186) 201-9229|42362|TN   |USA    |Event          |\n",
      "|394554865|797030169|3026  |0        |8/9/01       |(463) 615-3414|58861|OH   |USA    |Friend         |\n",
      "|394554865|913836222|745117|0        |8/9/01       |(473) 114-4879|58861|OH   |USA    |Friend         |\n",
      "|394554865|704469483|170768|0        |8/9/01       |(287) 621-8128|58861|OH   |USA    |Friend         |\n",
      "|512235277|359947731|460979|1        |11/8/99      |(627) 206-3723|93764|OK   |USA    |Event          |\n",
      "|512235277|809426292|846482|1        |11/8/99      |(789) 569-1859|93764|OK   |USA    |Event          |\n",
      "|512235277|227697877|5880  |1        |11/8/99      |(532) 863-8549|93764|OK   |USA    |Event          |\n",
      "|512235277|256073394|259712|1        |11/8/99      |(974) 928-1372|93764|OK   |USA    |Event          |\n",
      "|512235277|292628930|806469|1        |11/8/99      |(436) 953-1448|93764|OK   |USA    |Event          |\n",
      "|512235277|358571799|902851|1        |11/8/99      |(960) 451-4095|93764|OK   |USA    |Event          |\n",
      "|512235277|881653164|5847  |1        |11/8/99      |(984) 375-2739|93764|OK   |USA    |Event          |\n",
      "|710134819|778588525|331216|1        |9/16/92      |(959) 701-6373|50311|SD   |USA    |Advertisement  |\n",
      "|710134819|383307742|42135 |1        |9/16/92      |(248) 927-4029|50311|SD   |USA    |Advertisement  |\n",
      "|728423971|267907442|199064|1        |9/8/18       |(766) 704-5314|22605|WA   |USA    |Event          |\n",
      "|728423971|562069432|54071 |1        |9/8/18       |(455) 354-8214|22605|WA   |USA    |Event          |\n",
      "|728423971|893938023|128042|1        |9/8/18       |(615) 643-9972|22605|WA   |USA    |Event          |\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect duplicates in HOUSEHOLDS DataFrame\n",
    "inspect_duplicates(households_df, \"hh_id\", \"HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate count for hh_id: 131352\n",
      "Duplicate count for hh_id + cust_id: 0\n",
      "Duplicate count for hh_id + car_id: 0\n",
      "Duplicate count for hh_id + cust_id + car_id: 0\n"
     ]
    }
   ],
   "source": [
    "# Check and print duplicate count based on a combination of columns\n",
    "def check_combination_duplicates(df, columns, combination_name):\n",
    "    duplicate_count = df.groupBy(columns).count().filter(\"count > 1\").count()\n",
    "    print(f\"Duplicate count for {combination_name}: {duplicate_count}\")\n",
    "\n",
    "# Checking duplicates for different combinations of columns\n",
    "check_combination_duplicates(households_df, [\"hh_id\"], \"hh_id\")\n",
    "check_combination_duplicates(households_df, [\"hh_id\", \"cust_id\"], \"hh_id + cust_id\")\n",
    "check_combination_duplicates(households_df, [\"hh_id\", \"car_id\"], \"hh_id + car_id\")\n",
    "check_combination_duplicates(households_df, [\"hh_id\", \"cust_id\", \"car_id\"], \"hh_id + cust_id + car_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "\n",
    "- **The above results indicate that 26% of the hh_ids are duplicates, as each household may have more than one car and insurance policy.**\n",
    "\n",
    "- **A combination of hh_id and cust_id could be used as the primary key.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***DQ Checks for HOUSEHOLDS DataFrame:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid cust_id:\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|  cust_id|    hh_id|car_id|active_hh|hh_start_date|  phone_number|  zip|state|country|referral_source|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "|774461007|739569792|640160|        0|       8/1/81|(678) 123-4567|54321|   GA|    USA|          Other|\n",
      "+---------+---------+------+---------+-------------+--------------+-----+-----+-------+---------------+\n",
      "\n",
      "Sample Invalid hh_start_dates:\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "|hh_id|cust_id|car_id|active_hh|hh_start_date|phone_number|zip|state|country|referral_source|\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "\n",
      "+---------------+\n",
      "|referral_source|\n",
      "+---------------+\n",
      "|Event          |\n",
      "|Email          |\n",
      "|Other          |\n",
      "|Social Media   |\n",
      "|Website        |\n",
      "|Friend         |\n",
      "|Advertisement  |\n",
      "+---------------+\n",
      "\n",
      "Null cust_id count: 0\n",
      "Invalid cust_id count: 1\n",
      "Null car_id count: 0\n",
      "Invalid car_id count: 0\n",
      "Invalid active_hh count: 0\n",
      "Invalid hh_start_date count: 0\n",
      "Invalid phone number count: 0\n",
      "Invalid zip count: 0\n",
      "Invalid state count: 0\n",
      "Invalid country count: 0\n",
      "Null referral_source count: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "# cust_id - Null check\n",
    "cust_id_null_count = households_df.filter(col(\"cust_id\").isNull()).count()\n",
    "invalid_cust_id_df = households_df.join(customers_df, on=\"cust_id\", how=\"left_anti\")\n",
    "print(\"Invalid cust_id:\")\n",
    "invalid_cust_id_df.show()\n",
    "invalid_cust_id_count = invalid_cust_id_df.count()\n",
    "\n",
    "# car_id - Null check\n",
    "car_id_null_count = households_df.filter(col(\"car_id\").isNull()).count()\n",
    "invalid_car_id_count = households_df.join(cars_df, on=\"car_id\", how=\"left_anti\").count()\n",
    "\n",
    "# Check for invalid active_hh values\n",
    "invalid_active_hh_count = households_df.filter(~col(\"active_hh\").isin([0, 1])).count()\n",
    "\n",
    "# Check for invalid date format or invalid date\n",
    "invalid_hh_start_date_df = households_df.filter(\n",
    "    (regexp_extract(col(\"hh_start_date\"), r\"^\\d{1,2}/\\d{1,2}/\\d{2}$\", 0) == \"\") |\n",
    "    (to_date(col(\"hh_start_date\"), \"M/d/yy\").isNull()) |\n",
    "    (to_date(col(\"hh_start_date\"), \"M/d/yy\") > date_format(current_date(), \"M/d/yy\"))\n",
    ")\n",
    "print(\"Sample Invalid hh_start_dates:\")\n",
    "invalid_hh_start_date_df.show(5)\n",
    "invalid_hh_start_date_count = invalid_hh_start_date_df.count()\n",
    "\n",
    "# Check for invalid phone number format\n",
    "invalid_phone_number_count = households_df.filter(~col(\"phone_number\").rlike(r\"^\\(\\d{3}\\) \\d{3}-\\d{4}$\")).count()\n",
    "\n",
    "# Check for invalid zip code format\n",
    "invalid_zip_count = households_df.filter(~col(\"zip\").rlike(r\"^\\d{5}$\")).count()\n",
    "\n",
    "# List of valid U.S. states\n",
    "valid_states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "# Check for invalid state codes\n",
    "invalid_state_count = households_df.filter(~col(\"state\").isin(valid_states)).count()\n",
    "\n",
    "# Check for invalid country value (assuming only 'USA' is valid)\n",
    "invalid_country_count = households_df.filter(col(\"country\") != \"USA\").count()\n",
    "\n",
    "# Check for null values in referral_source\n",
    "referral_source_null_count = households_df.filter(col(\"referral_source\").isNull()).count()\n",
    "distinct_referral_source_values = households_df.select(\"referral_source\").distinct()\n",
    "distinct_referral_source_values.show(truncate=False)\n",
    "\n",
    "\n",
    "print(f\"Null cust_id count: {cust_id_null_count}\")\n",
    "print(f\"Invalid cust_id count: {invalid_cust_id_count}\")\n",
    "print(f\"Null car_id count: {car_id_null_count}\")\n",
    "print(f\"Invalid car_id count: {invalid_car_id_count}\")\n",
    "print(f\"Invalid active_hh count: {invalid_active_hh_count}\")\n",
    "print(f\"Invalid hh_start_date count: {invalid_hh_start_date_count}\")\n",
    "print(f\"Invalid phone number count: {invalid_phone_number_count}\")\n",
    "print(f\"Invalid zip count: {invalid_zip_count}\")\n",
    "print(f\"Invalid state count: {invalid_state_count}\")\n",
    "print(f\"Invalid country count: {invalid_country_count}\")\n",
    "print(f\"Null referral_source count: {referral_source_null_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "\n",
    "- **One cust_id from the HOUSEHOLD DataFrame is not present in the CUSTOMERS DataFrame.**\n",
    "- **This record will be excluded from the HOUSEHOLD DataFrame, as there is no information about that customer.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "new HOUSEHOLDS DataFrame:\n",
      "#################### \n",
      "\n",
      "-----------------------------------\n",
      "Null counts for new HOUSEHOLDS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "|hh_id|cust_id|car_id|active_hh|hh_start_date|phone_number|zip|state|country|referral_source|\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "|    0|      0|     0|        0|            0|           0|  0|    0|      0|              0|\n",
      "+-----+-------+------+---------+-------------+------------+---+-----+-------+---------------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in new HOUSEHOLDS DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "499999\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_households_df = households_df.filter(households_df.cust_id != 774461007)\n",
    "calculate_null_counts(new_households_df, \"new HOUSEHOLDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: orange;\"> 4. Combine the Datasets into One DataFrame </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+---------+---------+-------------+--------------+-----+-------+---------------+-------------+--------------+---------------------------------+------+--------+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|state|cust_id  |hh_id    |active_hh|hh_start_date|phone_number  |zip  |country|referral_source|date_of_birth|marital_status|employment_type                  |income|status  |model_year|make         |body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+-----+---------+---------+---------+-------------+--------------+-----+-------+---------------+-------------+--------------+---------------------------------+------+--------+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|555   |IN   |306774103|794928445|1        |11/1/90      |(745) 856-3796|48315|USA    |Event          |5/19/08      |S             |Business and Financial Operations|85202 |In Force|2024      |Manufacturer1|SUV       |51862.0      |29445              |1           |0              |1   |0    |0                     |0                      |0           |459.7643348             |\n",
      "|789   |MO   |623265167|284360589|1        |10/7/18      |(620) 644-8569|26636|USA    |Friend         |11/9/95      |D             |Healthcare Practitioner          |190943|In Force|2017      |Manufacturer6|4 door    |32345.95     |11836              |0           |0              |1   |0    |0                     |1                      |0           |73.21465538             |\n",
      "|1006  |LA   |236212139|949833788|1        |4/28/89      |(125) 998-8819|11368|USA    |Social Media   |11/21/80     |S             |Information Technology           |133677|In Force|2012      |Manufacturer1|SUV       |16039.6      |72914              |1           |0              |1   |0    |0                     |1                      |0           |81.47090769             |\n",
      "|1006  |ND   |786399554|719609959|1        |12/20/95     |(666) 994-4674|24278|USA    |Email          |1/18/71      |M             |Office and Administrative Support|37956 |In Force|2022      |Manufacturer6|4 door    |53057.7      |50850              |0           |0              |0   |0    |0                     |1                      |0           |330.7160793             |\n",
      "|1007  |NM   |358644120|468474699|0        |9/29/18      |(602) 647-6247|41501|USA    |Event          |8/19/37      |M             |Retired                          |0     |In Force|2019      |Manufacturer7|4 door    |33267.75     |12176              |0           |0              |0   |1    |1                     |1                      |0           |173.7025393             |\n",
      "+------+-----+---------+---------+---------+-------------+--------------+-----+-------+---------------+-------------+--------------+---------------------------------+------+--------+----------+-------------+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join households_df with new_cust_df on cust_id\n",
    "households_customers_df = new_households_df.join(new_cust_df, on=\"cust_id\", how=\"inner\")\n",
    "\n",
    "# Join the result with cars_df on [car_id, state]\n",
    "final_df = households_customers_df.join(cars_df, on=[\"car_id\", \"state\"], how=\"inner\")\n",
    "\n",
    "final_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "FINAL DataFrame:\n",
      "#################### \n",
      "\n",
      "-----------------------------------\n",
      "Null counts for FINAL DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "+------+-----+-------+-----+---------+-------------+------------+---+-------+---------------+-------------+--------------+---------------+------+------+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|car_id|state|cust_id|hh_id|active_hh|hh_start_date|phone_number|zip|country|referral_source|date_of_birth|marital_status|employment_type|income|status|model_year|make|body_style|vehicle_value|annual_miles_driven|business_use|antique_vehicle|lien|lease|driver_safety_discount|vehicle_safety_discount|claim_payout|six_month_premium_amount|\n",
      "+------+-----+-------+-----+---------+-------------+------------+---+-------+---------------+-------------+--------------+---------------+------+------+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "|     0|    0|      0|    0|        0|            0|           0|  0|      0|              0|            0|             0|              0|     0|     0|         0|   0|         0|            0|                  0|           0|              0|   0|    0|                     0|                      0|           0|                       0|\n",
      "+------+-----+-------+-----+---------+-------------+------------+---+-------+---------------+-------------+--------------+---------------+------+------+----------+----+----------+-------------+-------------------+------------+---------------+----+-----+----------------------+-----------------------+------------+------------------------+\n",
      "\n",
      "-----------------------------------\n",
      "Total rows in FINAL DataFrame:\n",
      "----------------------------------- \n",
      "\n",
      "499999\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_null_counts(final_df, \"FINAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 129.69944763183594 MB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import sys\n",
    "\n",
    "# Function to calculate the size of a DataFrame in memory\n",
    "def get_df_size_in_memory(df: DataFrame) -> float:\n",
    "    partition_sizes = df.rdd.mapPartitions(lambda iter: [sum(sys.getsizeof(row) for row in iter)]).collect()    # Calculate the size of each partition\n",
    "    total_size = sum(partition_sizes)               # Total size in bytes\n",
    "    total_size_in_mb = total_size / (1024 * 1024)   # Convert size to megabytes\n",
    "    return total_size_in_mb\n",
    "\n",
    "df_size_in_mb = get_df_size_in_memory(final_df)\n",
    "print(f\"DataFrame size: {df_size_in_mb} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7a77421ed90e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SF-Data-Engineering-Work-Sample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffd8acdd50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count for column 'car_id': 372536\n",
      "Distinct count for column 'state': 50\n",
      "Distinct count for column 'cust_id': 499850\n",
      "Distinct count for column 'hh_id': 131352\n",
      "Distinct count for column 'active_hh': 2\n",
      "Distinct count for column 'hh_start_date': 12774\n",
      "Distinct count for column 'phone_number': 499984\n",
      "Distinct count for column 'zip': 69148\n",
      "Distinct count for column 'country': 1\n",
      "Distinct count for column 'referral_source': 7\n",
      "Distinct count for column 'date_of_birth': 28560\n",
      "Distinct count for column 'marital_status': 4\n",
      "Distinct count for column 'employment_type': 10\n",
      "Distinct count for column 'income': 119552\n",
      "Distinct count for column 'status': 4\n",
      "Distinct count for column 'model_year': 73\n",
      "Distinct count for column 'make': 7\n",
      "Distinct count for column 'body_style': 4\n",
      "Distinct count for column 'vehicle_value': 209693\n",
      "Distinct count for column 'annual_miles_driven': 92634\n",
      "Distinct count for column 'business_use': 2\n",
      "Distinct count for column 'antique_vehicle': 2\n",
      "Distinct count for column 'lien': 2\n",
      "Distinct count for column 'lease': 2\n",
      "Distinct count for column 'driver_safety_discount': 2\n",
      "Distinct count for column 'vehicle_safety_discount': 2\n",
      "Distinct count for column 'claim_payout': 3697\n",
      "Distinct count for column 'six_month_premium_amount': 499979\n"
     ]
    }
   ],
   "source": [
    "# Inspecting count of distinct values in each column to determine potential partitioning columns\n",
    "columns_to_check = ['car_id', 'state', 'cust_id', 'hh_id', 'active_hh', 'hh_start_date', 'phone_number', 'zip', \n",
    "                    'country', 'referral_source', 'date_of_birth', 'marital_status', 'employment_type', 'income', \n",
    "                    'status', 'model_year', 'make', 'body_style', 'vehicle_value', 'annual_miles_driven', 'business_use',\n",
    "                    'antique_vehicle', 'lien', 'lease', 'driver_safety_discount', 'vehicle_safety_discount', 'claim_payout', \n",
    "                    'six_month_premium_amount']\n",
    "                    \n",
    "for column in columns_to_check:\n",
    "    distinct_count = final_df.select(column).distinct().count()\n",
    "    print(f\"Distinct count for column '{column}': {distinct_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|state|record_count|\n",
      "+-----+------------+\n",
      "|   KY|       10519|\n",
      "|   SC|       10453|\n",
      "|   AK|       10401|\n",
      "|   HI|       10356|\n",
      "|   WY|       10327|\n",
      "|   CT|       10326|\n",
      "|   NE|       10295|\n",
      "|   MI|       10272|\n",
      "|   MA|       10266|\n",
      "|   AR|       10207|\n",
      "|   MN|       10204|\n",
      "|   GA|       10185|\n",
      "|   WA|       10184|\n",
      "|   AL|       10175|\n",
      "|   NY|       10154|\n",
      "|   NV|       10148|\n",
      "|   CA|       10110|\n",
      "|   MS|       10061|\n",
      "|   NJ|       10058|\n",
      "|   MO|       10044|\n",
      "|   NM|       10040|\n",
      "|   IN|       10030|\n",
      "|   MT|       10029|\n",
      "|   AZ|        9988|\n",
      "|   UT|        9986|\n",
      "|   FL|        9963|\n",
      "|   SD|        9961|\n",
      "|   OH|        9945|\n",
      "|   RI|        9936|\n",
      "|   ND|        9921|\n",
      "|   IL|        9920|\n",
      "|   MD|        9911|\n",
      "|   OR|        9908|\n",
      "|   TX|        9901|\n",
      "|   NC|        9878|\n",
      "|   IA|        9855|\n",
      "|   WV|        9849|\n",
      "|   NH|        9810|\n",
      "|   VA|        9808|\n",
      "|   LA|        9802|\n",
      "|   KS|        9775|\n",
      "|   ME|        9748|\n",
      "|   OK|        9740|\n",
      "|   DE|        9712|\n",
      "|   VT|        9699|\n",
      "|   WI|        9688|\n",
      "|   PA|        9645|\n",
      "|   TN|        9633|\n",
      "|   CO|        9590|\n",
      "|   ID|        9583|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For \"state\"\n",
    "state_partition_count = final_df.groupBy(\"state\").agg(F.count(\"*\").alias(\"record_count\")).orderBy(\"record_count\", ascending=False)\n",
    "state_partition_count.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|model_year|record_count|\n",
      "+----------+------------+\n",
      "|      2024|       16405|\n",
      "|      2023|       16148|\n",
      "|      2022|       16212|\n",
      "|      2021|       16477|\n",
      "|      2020|       16065|\n",
      "|      2019|       16074|\n",
      "|      2018|       16143|\n",
      "|      2017|       16393|\n",
      "|      2016|       16445|\n",
      "|      2015|       16478|\n",
      "|      2014|       16268|\n",
      "|      2013|       16258|\n",
      "|      2012|       16114|\n",
      "|      2011|       16522|\n",
      "|      2010|       16108|\n",
      "|      2009|       16389|\n",
      "|      2008|       16334|\n",
      "|      2007|       16269|\n",
      "|      2006|       16220|\n",
      "|      2005|       16345|\n",
      "|      2004|       16464|\n",
      "|      2003|       16194|\n",
      "|      2002|       16298|\n",
      "|      2001|        2489|\n",
      "|      2000|        2450|\n",
      "|      1999|        2523|\n",
      "|      1998|        2521|\n",
      "|      1997|        2533|\n",
      "|      1996|        2497|\n",
      "|      1995|        2532|\n",
      "|      1994|        2522|\n",
      "|      1993|        2456|\n",
      "|      1992|        2446|\n",
      "|      1991|        2498|\n",
      "|      1990|        2516|\n",
      "|      1989|        2542|\n",
      "|      1988|        2480|\n",
      "|      1987|        2465|\n",
      "|      1986|        2544|\n",
      "|      1985|        2450|\n",
      "|      1984|        2515|\n",
      "|      1983|        2531|\n",
      "|      1982|        2544|\n",
      "|      1981|        2590|\n",
      "|      1980|        2416|\n",
      "|      1979|        2494|\n",
      "|      1978|        2538|\n",
      "|      1977|        2496|\n",
      "|      1976|        2569|\n",
      "|      1975|        2552|\n",
      "|      1974|        2469|\n",
      "|      1973|        2464|\n",
      "|      1972|        2545|\n",
      "|      1971|        2528|\n",
      "|      1970|        2496|\n",
      "|      1969|        2498|\n",
      "|      1968|        2443|\n",
      "|      1967|        2542|\n",
      "|      1966|        2420|\n",
      "|      1965|        2505|\n",
      "|      1964|        2495|\n",
      "|      1963|        2476|\n",
      "|      1962|        2560|\n",
      "|      1961|        2496|\n",
      "|      1960|        2492|\n",
      "|      1959|        2512|\n",
      "|      1958|        2582|\n",
      "|      1957|        2495|\n",
      "|      1956|        2516|\n",
      "|      1955|        2515|\n",
      "|      1954|        2585|\n",
      "|      1953|        2512|\n",
      "|      1952|        2521|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For \"model_year\"\n",
    "model_year_partition_count = final_df.groupBy(\"model_year\").agg(F.count(\"*\").alias(\"record_count\")).orderBy(\"model_year\", ascending=False)\n",
    "model_year_partition_count.show(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|         make|record_count|\n",
      "+-------------+------------+\n",
      "|Manufacturer2|      100020|\n",
      "|Manufacturer3|       99986|\n",
      "|Manufacturer1|       99772|\n",
      "|Manufacturer6|       65297|\n",
      "|Manufacturer7|       65243|\n",
      "|Manufacturer5|       34850|\n",
      "|Manufacturer4|       34831|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_partition_count = final_df.groupBy(\"make\").agg(F.count(\"*\").alias(\"record_count\")).orderBy(\"record_count\", ascending=False)\n",
    "make_partition_count.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<u style=\"color: green;\">OBSERVATION:</u> &nbsp;***\n",
    "\n",
    "- **'state' appears to be a good partitioning column, as the data is almost evenly distributed across the states.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to parquet\n",
    "final_df.coalesce(1).write.partitionBy(\"state\") \\\n",
    "        .parquet(f\"{OUTPUT_DIR}/final_df.parquet\", mode=\"overwrite\", compression=\"snappy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
